{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda activate: /data_disk/home/taein/.conda/envs/Gesture\n",
      "Python version: 3.9.18 (main, Sep 11 2023, 13:41:44) \n",
      "[GCC 11.2.0]\n",
      "cv2 version: 4.8.1\n",
      "mediapipe version 0.10.7\n",
      "pandas version: 2.0.3\n",
      "numpy version: 1.26.0\n",
      "torch version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "# conda activate Gseture\n",
    "print('conda activate:', sys.prefix)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"cv2 version:\", cv2.__version__)\n",
    "print(\"mediapipe version\", mp.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 경로 import class명\n",
    "from main_files.CustomDataset import CustomDataset\n",
    "from main_files.model import CNN_LSTM\n",
    "\n",
    "\n",
    "# 필요한 모듈\n",
    "import torch.nn as nn  \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # 진행바\n",
    "from torch.utils.data import Dataset,DataLoader ,random_split\n",
    "from torchinfo import summary # 모델 요약\n",
    "from tensorboardX import SummaryWriter # 텐서보드 (loss,accuracy 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 7714 \n",
      "\n",
      "Traing data size: 6172\n",
      "Validation data size: 1542 \n",
      "\n",
      "Traing data # of batch: 97\n",
      "Validation # of batch: 25\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "##   데이터셋 생성\n",
    "##\n",
    "\n",
    "dataset=CustomDataset(window_size=30, Folder_dir='./main_data/')\n",
    "\n",
    "# train,test 분리\n",
    "val_ratio=0.2\n",
    "val_size=int(val_ratio*len(dataset))\n",
    "\n",
    "train_size=len(dataset)-val_size\n",
    "train_dataset, val_dataset=random_split(dataset,[train_size,val_size])\n",
    "\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=64,shuffle=True)  # shuffle: 미니배치들이 에폭마다 섞이는 유무.\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=64,shuffle=False)  # shuffle: 미니배치들이 에폭마다 섞이는 유무.\n",
    "\n",
    "print(\"Dataset size:\",len(dataset),'\\n')\n",
    "print(\"Traing data size:\",len(train_dataset))\n",
    "print(\"Validation data size:\",len(val_dataset),'\\n')   \n",
    "print(\"Traing data # of batch:\",len(train_dataloader))\n",
    "print(\"Validation # of batch:\",len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, train_loader,device,optimizer,loss_func,log_interval=10):\n",
    "    model_name.train()\n",
    "    Train_total_loss=0\n",
    "    Train_correct_predictions=0\n",
    "\n",
    "    for batch_idx,(x_train, y_train) in enumerate(tqdm(train_loader)):\n",
    "        # cross entropy의 y는 LongTensor형이어야 함.\n",
    "        y_train=y_train.type(torch.LongTensor)\n",
    "        x_train=x_train.to(device)\n",
    "        y_train=y_train.to(device)\n",
    "\n",
    "\n",
    "\n",
    "        y_predict=model_name(x_train)\n",
    "        \n",
    "        # loss 계산\n",
    "        loss=loss_func(y_predict,y_train.squeeze(dim=-1))\n",
    "        Train_total_loss+=loss.item()\n",
    "\n",
    "        # 정확도 계싼\n",
    "        values, indices = torch.max(y_predict.data, dim=1,keepdim=True)\n",
    "        Train_correct_predictions += (indices == y_train).sum().item()\n",
    "\n",
    "        # 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch_idx % log_interval==0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch,batch_idx*len(x_train),len(train_dataloader.dataset),\n",
    "        #         100.*batch_idx/len(train_dataloader.dataset),loss.item()\n",
    "        #     ))\n",
    "\n",
    "    avg_train_loss=Train_total_loss/len(train_loader.dataset)\n",
    "    Train_accuracy = 100. * Train_correct_predictions / len(train_loader.dataset)\n",
    "    print('Train Epoch: {} Average loss: {:.6f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch, avg_train_loss, Train_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model_name,test_loader,device,loss_func):\n",
    "    model_name.eval()\n",
    "    correct=0\n",
    "    val_loss=0\n",
    "    with torch.no_grad():\n",
    "        for idx,(x_test,y_test) in enumerate(test_loader):\n",
    "            y_test=y_test.type(torch.LongTensor)\n",
    "            x_test=x_test.to(device)\n",
    "            y_test=y_test.to(device)  # torch.Size([64, 1])\n",
    "            \n",
    "            y_pred=model_name(x_test)\n",
    "            \n",
    "            val_loss+=loss_func(y_pred,y_test.squeeze(dim=-1)).item()\n",
    "\n",
    "            # 정확하게 분류한 샘플 수 계산\n",
    "            values, indices = torch.max(y_pred.data, dim=1,keepdim=True)        \n",
    "            correct += (indices == y_test).sum().item()\n",
    "\n",
    "            # print('y_test :',y_test.shape)     # torch.Size([64, 1])\n",
    "            # print('indices: ',indices.shape)   # torch.Size([64, 1]) \n",
    "\n",
    "    avg_val_loss=val_loss/len(test_loader.dataset)\n",
    "    accuracy = 100 * correct / len(test_loader.dataset)  # 정확도 계산\n",
    "    print('Validation set: Average loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(avg_val_loss, accuracy))\n",
    "    print()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_disk/home/taein/.conda/envs/Gesture/lib/python3.9/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "\n",
    "# 모델 호출\n",
    "CNN_LSTM_model=CNN_LSTM(\n",
    "                input_size=99, \n",
    "                output_size=64,\n",
    "                units=32).to(device)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.Adam(CNN_LSTM_model.parameters(), lr=0.0001)\n",
    "\n",
    "# loss 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# epoch 설정\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_disk/home/taein/Unmanned_Vehicle/HMI/Gesture_Recogntion/main_files/model.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x=self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_LSTM                                 [64, 4]                   --\n",
       "├─Conv1d: 1-1                            [64, 64, 28]              19,072\n",
       "├─ReLU: 1-2                              [64, 64, 28]              --\n",
       "├─LSTM: 1-3                              [64, 28, 32]              12,544\n",
       "├─Linear: 1-4                            [64, 4]                   132\n",
       "├─Softmax: 1-5                           [64, 4]                   --\n",
       "==========================================================================================\n",
       "Total params: 31,748\n",
       "Trainable params: 31,748\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 56.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.76\n",
       "Forward/backward pass size (MB): 1.38\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 2.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(CNN_LSTM_model, (64,30,99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:01<00:00, 63.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Average loss: 0.021101, Accuracy: 50.63%\n",
      "Validation set: Average loss: 0.0210, Accuracy: 68.55%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 111.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Average loss: 0.019686, Accuracy: 71.81%\n",
      "Validation set: Average loss: 0.0198, Accuracy: 70.69%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 123.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 Average loss: 0.018585, Accuracy: 72.60%\n",
      "Validation set: Average loss: 0.0184, Accuracy: 71.01%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 133.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Average loss: 0.017122, Accuracy: 73.09%\n",
      "Validation set: Average loss: 0.0172, Accuracy: 75.55%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 129.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Average loss: 0.016092, Accuracy: 83.25%\n",
      "Validation set: Average loss: 0.0163, Accuracy: 88.91%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 138.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Average loss: 0.015351, Accuracy: 91.14%\n",
      "Validation set: Average loss: 0.0156, Accuracy: 92.67%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 126.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 Average loss: 0.014792, Accuracy: 93.52%\n",
      "Validation set: Average loss: 0.0151, Accuracy: 95.14%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 128.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 Average loss: 0.014399, Accuracy: 95.64%\n",
      "Validation set: Average loss: 0.0149, Accuracy: 94.94%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 131.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 Average loss: 0.014010, Accuracy: 97.50%\n",
      "Validation set: Average loss: 0.0144, Accuracy: 97.86%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 118.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Average loss: 0.013701, Accuracy: 98.35%\n",
      "Validation set: Average loss: 0.0141, Accuracy: 98.57%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 128.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 Average loss: 0.013471, Accuracy: 98.80%\n",
      "Validation set: Average loss: 0.0138, Accuracy: 98.64%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 134.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 Average loss: 0.013222, Accuracy: 99.21%\n",
      "Validation set: Average loss: 0.0136, Accuracy: 98.96%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 131.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 Average loss: 0.013018, Accuracy: 99.30%\n",
      "Validation set: Average loss: 0.0134, Accuracy: 98.64%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 137.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 Average loss: 0.012854, Accuracy: 99.40%\n",
      "Validation set: Average loss: 0.0133, Accuracy: 98.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 122.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 Average loss: 0.012711, Accuracy: 99.51%\n",
      "Validation set: Average loss: 0.0131, Accuracy: 99.48%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 130.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 Average loss: 0.012567, Accuracy: 99.63%\n",
      "Validation set: Average loss: 0.0129, Accuracy: 99.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 130.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 Average loss: 0.012456, Accuracy: 99.69%\n",
      "Validation set: Average loss: 0.0128, Accuracy: 99.74%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 115.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 Average loss: 0.012371, Accuracy: 99.77%\n",
      "Validation set: Average loss: 0.0127, Accuracy: 99.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 134.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 Average loss: 0.012290, Accuracy: 99.87%\n",
      "Validation set: Average loss: 0.0127, Accuracy: 99.81%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 127.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 Average loss: 0.012231, Accuracy: 99.90%\n",
      "Validation set: Average loss: 0.0126, Accuracy: 99.94%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 118.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 Average loss: 0.012180, Accuracy: 99.92%\n",
      "Validation set: Average loss: 0.0126, Accuracy: 99.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 124.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 Average loss: 0.012130, Accuracy: 99.95%\n",
      "Validation set: Average loss: 0.0125, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 118.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 Average loss: 0.012086, Accuracy: 99.95%\n",
      "Validation set: Average loss: 0.0125, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 131.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 Average loss: 0.012050, Accuracy: 99.97%\n",
      "Validation set: Average loss: 0.0124, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 126.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 Average loss: 0.012017, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0124, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 117.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 Average loss: 0.011992, Accuracy: 99.98%\n",
      "Validation set: Average loss: 0.0124, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 130.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 Average loss: 0.011967, Accuracy: 99.98%\n",
      "Validation set: Average loss: 0.0123, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 124.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 Average loss: 0.011943, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0123, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 124.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 Average loss: 0.011923, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0123, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 121.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 Average loss: 0.011903, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0123, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gesture={\n",
    "    0 : 'Right',\n",
    "    1 : 'Left',\n",
    "    2 : 'Turn Clockwise',\n",
    "    3 : 'Turn Anticlockwise'\n",
    "\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train(\n",
    "        model_name=CNN_LSTM_model, \n",
    "        train_loader=train_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=criterion,\n",
    "        log_interval=1,\n",
    "        device=device,)\n",
    "\n",
    "    evaluate(\n",
    "        model_name=CNN_LSTM_model,\n",
    "        test_loader=val_dataloader,\n",
    "        loss_func=criterion,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN_LSTM_model.state_dict(), './main_models/model_dict().pt')\n",
    "torch.save(CNN_LSTM_model, './main_models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이해안되는 부분 확인중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[0.0168, 0.3880, 0.9685],\n",
      "        [0.9958, 0.9044, 0.3451],\n",
      "        [0.5561, 0.8403, 0.7750],\n",
      "        [0.7458, 0.1477, 0.5786]])\n",
      "tensor([[0.9685],\n",
      "        [0.9958],\n",
      "        [0.8403],\n",
      "        [0.7458]])\n",
      "tensor([[2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 예측 출력을 나타내는 무작위 텐서 생성 (예시)\n",
    "# 가정: 모델의 출력이 3개의 클래스를 분류하며, 배치 크기가 4인 경우\n",
    "y_pred = torch.rand(4, 3)\n",
    "\n",
    "# y_pred 텐서의 내용 확인\n",
    "print(y_pred.shape)\n",
    "print(y_pred)\n",
    "\n",
    "# 각 샘플에 대한 최대 클래스 인덱스 찾기\n",
    "values, indices = torch.max(y_pred,dim=1, keepdim=True)\n",
    "# dim=1: 행을 따라 최대값 찾기, dim=0: 열을 따라 최대값 찾기\n",
    "# keepdim=True: 출력 텐서각각을 크기가1인 차원으로 유지함.\n",
    "# keepdim=False: 출력 텐서 각각의 크기가 1인 차원을 삭제함.\n",
    "\n",
    "\n",
    "# predicted 텐서의 내용 확인\n",
    "print(values)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배움\n",
    "\n",
    "1. .item()  : 텐서의 값을 일반 파이썬 스칼라값(float등)으로 변환해줌\n",
    "\n",
    "2. crossentropy수행시 y의 값은 LongTensor (=int=정수형) 로 들어가야함.\n",
    "\n",
    "3. torch.max : 분류문제에서 정확도및 loss값 확인하려고 사용함\n",
    "\n",
    "4. - len(test_loader.dataset) : 전체 데이터 셋의 개수, \n",
    "   - len(test_loader) : 하나의 배치의 수.\n",
    "\n",
    "5. torchinfo : 모델정보를 볼수 있음. \n",
    "   - pip install torchinfo\n",
    "   - from torchinfo import summary\n",
    "   - summary(model_name , (batch size, input size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gesture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
